{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Old Homes\n",
    "\n",
    "Now that we have explored our data, and cleaned it up into an acceptable format, we are ready to run some modeling techniques on it. We will begin by building multiple generic models on the data set to see how well it performs. After this, we will build a Neural Network to see if we can improve the performance from the baseline models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset\n",
    "\n",
    "This dataset is already cleaned up and preprocessed. It is expected that this dataset has the following columns:\n",
    "* SALEPRICE\n",
    "\n",
    "> NOTE/TODO: Currently, we don't do anything with the PROPERTYZIP. We plan to build a model for each zipcode, but that is pending our preliminary results (to see if we need to even attempt such a thing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "data = pd.read_csv('Dataset_v4.csv')\n",
    "\n",
    "# Renaming columns to not include brackets, spaces, or commas\n",
    "column_mapping = {}\n",
    "for col in list(data.columns):\n",
    "\n",
    "    new_col = col.replace(']', ')')\n",
    "    new_col = new_col.replace('[', '(')\n",
    "    new_col = new_col.replace(', ', '-')\n",
    "    new_col = new_col.replace(' ', '')\n",
    "    column_mapping[col] = new_col\n",
    "\n",
    "data = data.rename(columns=column_mapping)\n",
    "\n",
    "# Drop Nulls\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed:0</th>\n",
       "      <th>STYLE</th>\n",
       "      <th>ROOF</th>\n",
       "      <th>EXTFINISH</th>\n",
       "      <th>BASEMENT</th>\n",
       "      <th>STORIES</th>\n",
       "      <th>TOTALROOMS</th>\n",
       "      <th>BEDROOMS</th>\n",
       "      <th>FULLBATHS</th>\n",
       "      <th>HALFBATHS</th>\n",
       "      <th>FINISHEDLIVINGAREA</th>\n",
       "      <th>ZIPCODE</th>\n",
       "      <th>YEARSOLD</th>\n",
       "      <th>SALEDATE</th>\n",
       "      <th>PREVSALEPRICE</th>\n",
       "      <th>COUNTS</th>\n",
       "      <th>Condition</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>CDU</th>\n",
       "      <th>LOTAREA</th>\n",
       "      <th>COUNTYTOTAL</th>\n",
       "      <th>COUNTYBUILDING</th>\n",
       "      <th>COUNTYLAND</th>\n",
       "      <th>HOOD</th>\n",
       "      <th>FAIRMARKETTOTAL</th>\n",
       "      <th>FAIRMARKETBUILDING</th>\n",
       "      <th>FAIRMARKETLAND</th>\n",
       "      <th>LOCALTOTAL</th>\n",
       "      <th>LOCALBUILDING</th>\n",
       "      <th>LOCALLAND</th>\n",
       "      <th>SALEPRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1.14236</td>\n",
       "      <td>0.60914</td>\n",
       "      <td>1.434605</td>\n",
       "      <td>4.059843</td>\n",
       "      <td>-1.264172</td>\n",
       "      <td>-2.140282</td>\n",
       "      <td>-2.394149</td>\n",
       "      <td>-0.763327</td>\n",
       "      <td>0.796003</td>\n",
       "      <td>-0.529069</td>\n",
       "      <td>0.66975</td>\n",
       "      <td>-1.831685</td>\n",
       "      <td>-1.190679</td>\n",
       "      <td>2.227881</td>\n",
       "      <td>0.856116</td>\n",
       "      <td>0.057478</td>\n",
       "      <td>-4.048342</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.308912</td>\n",
       "      <td>1.500951</td>\n",
       "      <td>2.260345</td>\n",
       "      <td>-1.17797</td>\n",
       "      <td>-0.295931</td>\n",
       "      <td>1.364311</td>\n",
       "      <td>2.086146</td>\n",
       "      <td>-1.173912</td>\n",
       "      <td>1.366394</td>\n",
       "      <td>2.086146</td>\n",
       "      <td>-1.178275</td>\n",
       "      <td>394000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>1.14236</td>\n",
       "      <td>0.60914</td>\n",
       "      <td>1.434605</td>\n",
       "      <td>4.059843</td>\n",
       "      <td>-1.264172</td>\n",
       "      <td>-1.537534</td>\n",
       "      <td>-1.237946</td>\n",
       "      <td>0.782665</td>\n",
       "      <td>-0.947308</td>\n",
       "      <td>-0.296914</td>\n",
       "      <td>0.66975</td>\n",
       "      <td>-1.831685</td>\n",
       "      <td>-0.788398</td>\n",
       "      <td>-0.616199</td>\n",
       "      <td>1.198599</td>\n",
       "      <td>0.057478</td>\n",
       "      <td>-4.048342</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.308912</td>\n",
       "      <td>2.326323</td>\n",
       "      <td>3.279453</td>\n",
       "      <td>-1.17797</td>\n",
       "      <td>-0.295931</td>\n",
       "      <td>2.178665</td>\n",
       "      <td>3.091320</td>\n",
       "      <td>-1.173912</td>\n",
       "      <td>2.181724</td>\n",
       "      <td>3.091320</td>\n",
       "      <td>-1.178275</td>\n",
       "      <td>400000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>1.14236</td>\n",
       "      <td>0.60914</td>\n",
       "      <td>1.434605</td>\n",
       "      <td>4.059843</td>\n",
       "      <td>-1.264172</td>\n",
       "      <td>-2.140282</td>\n",
       "      <td>-2.394149</td>\n",
       "      <td>-0.763327</td>\n",
       "      <td>0.796003</td>\n",
       "      <td>-1.134329</td>\n",
       "      <td>0.66975</td>\n",
       "      <td>-1.831685</td>\n",
       "      <td>-1.238600</td>\n",
       "      <td>1.098978</td>\n",
       "      <td>1.535969</td>\n",
       "      <td>0.057478</td>\n",
       "      <td>-4.048342</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.308912</td>\n",
       "      <td>1.137932</td>\n",
       "      <td>1.812116</td>\n",
       "      <td>-1.17797</td>\n",
       "      <td>-0.295931</td>\n",
       "      <td>1.006137</td>\n",
       "      <td>1.644045</td>\n",
       "      <td>-1.173912</td>\n",
       "      <td>1.007791</td>\n",
       "      <td>1.644045</td>\n",
       "      <td>-1.178275</td>\n",
       "      <td>302000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126</td>\n",
       "      <td>1.14236</td>\n",
       "      <td>0.60914</td>\n",
       "      <td>1.434605</td>\n",
       "      <td>4.059843</td>\n",
       "      <td>-1.264172</td>\n",
       "      <td>-2.140282</td>\n",
       "      <td>-2.394149</td>\n",
       "      <td>0.782665</td>\n",
       "      <td>-0.947308</td>\n",
       "      <td>-0.516632</td>\n",
       "      <td>0.66975</td>\n",
       "      <td>-1.831685</td>\n",
       "      <td>-0.917027</td>\n",
       "      <td>3.200859</td>\n",
       "      <td>0.314278</td>\n",
       "      <td>0.057478</td>\n",
       "      <td>-4.048342</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.308912</td>\n",
       "      <td>2.085213</td>\n",
       "      <td>2.981748</td>\n",
       "      <td>-1.17797</td>\n",
       "      <td>-0.295931</td>\n",
       "      <td>2.101150</td>\n",
       "      <td>2.995642</td>\n",
       "      <td>-1.173912</td>\n",
       "      <td>2.104116</td>\n",
       "      <td>2.995642</td>\n",
       "      <td>-1.178275</td>\n",
       "      <td>425000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127</td>\n",
       "      <td>1.14236</td>\n",
       "      <td>0.60914</td>\n",
       "      <td>1.434605</td>\n",
       "      <td>4.059843</td>\n",
       "      <td>-1.264172</td>\n",
       "      <td>-1.537534</td>\n",
       "      <td>-1.237946</td>\n",
       "      <td>0.782665</td>\n",
       "      <td>-0.947308</td>\n",
       "      <td>-0.584344</td>\n",
       "      <td>0.66975</td>\n",
       "      <td>-1.831685</td>\n",
       "      <td>-0.784615</td>\n",
       "      <td>-0.601305</td>\n",
       "      <td>2.088030</td>\n",
       "      <td>0.057478</td>\n",
       "      <td>-4.048342</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.308912</td>\n",
       "      <td>1.432321</td>\n",
       "      <td>2.175606</td>\n",
       "      <td>-1.17797</td>\n",
       "      <td>-0.295931</td>\n",
       "      <td>1.456972</td>\n",
       "      <td>2.200520</td>\n",
       "      <td>-1.173912</td>\n",
       "      <td>1.459166</td>\n",
       "      <td>2.200520</td>\n",
       "      <td>-1.178275</td>\n",
       "      <td>300000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed:0    STYLE     ROOF  EXTFINISH  BASEMENT   STORIES  TOTALROOMS  \\\n",
       "0         11  1.14236  0.60914   1.434605  4.059843 -1.264172   -2.140282   \n",
       "1         75  1.14236  0.60914   1.434605  4.059843 -1.264172   -1.537534   \n",
       "2         82  1.14236  0.60914   1.434605  4.059843 -1.264172   -2.140282   \n",
       "3        126  1.14236  0.60914   1.434605  4.059843 -1.264172   -2.140282   \n",
       "4        127  1.14236  0.60914   1.434605  4.059843 -1.264172   -1.537534   \n",
       "\n",
       "   BEDROOMS  FULLBATHS  HALFBATHS  FINISHEDLIVINGAREA  ZIPCODE  YEARSOLD  \\\n",
       "0 -2.394149  -0.763327   0.796003           -0.529069  0.66975 -1.831685   \n",
       "1 -1.237946   0.782665  -0.947308           -0.296914  0.66975 -1.831685   \n",
       "2 -2.394149  -0.763327   0.796003           -1.134329  0.66975 -1.831685   \n",
       "3 -2.394149   0.782665  -0.947308           -0.516632  0.66975 -1.831685   \n",
       "4 -1.237946   0.782665  -0.947308           -0.584344  0.66975 -1.831685   \n",
       "\n",
       "   SALEDATE  PREVSALEPRICE    COUNTS  Condition     GRADE  CDU   LOTAREA  \\\n",
       "0 -1.190679       2.227881  0.856116   0.057478 -4.048342  4.0 -0.308912   \n",
       "1 -0.788398      -0.616199  1.198599   0.057478 -4.048342  4.0 -0.308912   \n",
       "2 -1.238600       1.098978  1.535969   0.057478 -4.048342  4.0 -0.308912   \n",
       "3 -0.917027       3.200859  0.314278   0.057478 -4.048342  4.0 -0.308912   \n",
       "4 -0.784615      -0.601305  2.088030   0.057478 -4.048342  4.0 -0.308912   \n",
       "\n",
       "   COUNTYTOTAL  COUNTYBUILDING  COUNTYLAND      HOOD  FAIRMARKETTOTAL  \\\n",
       "0     1.500951        2.260345    -1.17797 -0.295931         1.364311   \n",
       "1     2.326323        3.279453    -1.17797 -0.295931         2.178665   \n",
       "2     1.137932        1.812116    -1.17797 -0.295931         1.006137   \n",
       "3     2.085213        2.981748    -1.17797 -0.295931         2.101150   \n",
       "4     1.432321        2.175606    -1.17797 -0.295931         1.456972   \n",
       "\n",
       "   FAIRMARKETBUILDING  FAIRMARKETLAND  LOCALTOTAL  LOCALBUILDING  LOCALLAND  \\\n",
       "0            2.086146       -1.173912    1.366394       2.086146  -1.178275   \n",
       "1            3.091320       -1.173912    2.181724       3.091320  -1.178275   \n",
       "2            1.644045       -1.173912    1.007791       1.644045  -1.178275   \n",
       "3            2.995642       -1.173912    2.104116       2.995642  -1.178275   \n",
       "4            2.200520       -1.173912    1.459166       2.200520  -1.178275   \n",
       "\n",
       "   SALEPRICE  \n",
       "0   394000.0  \n",
       "1   400000.0  \n",
       "2   302000.0  \n",
       "3   425000.0  \n",
       "4   300000.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build two Models\n",
    "We have to types of homes:\n",
    "1. The home has a previous Sale Price.\n",
    "2. The home does not have a previous Sale Price.\n",
    "\n",
    "We believe that we can get better results if we build two models on these two datasets seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Model for Old Homes.\n",
    "data = data[data['PREVSALEPRICE'] != np.nan]\n",
    "\n",
    "print(\"Data Shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Validation/Test Split\n",
    "\n",
    "We will split our dataset into three sets:\n",
    "* Training - (77%)\n",
    "* Validation - (16.5%)\n",
    "* Testing - (16.5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape:  (55336, 29)\n",
      "Validation Shape:  (13628, 29)\n",
      "Testing Shape:  (13628, 29)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop(['Unnamed:0', 'SALEPRICE'], axis=1)\n",
    "Y = data['SALEPRICE']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle=True, random_state=100) # Reproducible\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, shuffle=True, random_state=100) # Reproducible\n",
    "\n",
    "print(\"Training Shape: \", X_train.shape)\n",
    "print(\"Validation Shape: \", X_val.shape)\n",
    "print(\"Testing Shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STYLE</th>\n",
       "      <th>ROOF</th>\n",
       "      <th>EXTFINISH</th>\n",
       "      <th>BASEMENT</th>\n",
       "      <th>STORIES</th>\n",
       "      <th>TOTALROOMS</th>\n",
       "      <th>BEDROOMS</th>\n",
       "      <th>FULLBATHS</th>\n",
       "      <th>HALFBATHS</th>\n",
       "      <th>FINISHEDLIVINGAREA</th>\n",
       "      <th>ZIPCODE</th>\n",
       "      <th>YEARSOLD</th>\n",
       "      <th>SALEDATE</th>\n",
       "      <th>PREVSALEPRICE</th>\n",
       "      <th>COUNTS</th>\n",
       "      <th>Condition</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>CDU</th>\n",
       "      <th>LOTAREA</th>\n",
       "      <th>COUNTYTOTAL</th>\n",
       "      <th>COUNTYBUILDING</th>\n",
       "      <th>COUNTYLAND</th>\n",
       "      <th>HOOD</th>\n",
       "      <th>FAIRMARKETTOTAL</th>\n",
       "      <th>FAIRMARKETBUILDING</th>\n",
       "      <th>FAIRMARKETLAND</th>\n",
       "      <th>LOCALTOTAL</th>\n",
       "      <th>LOCALBUILDING</th>\n",
       "      <th>LOCALLAND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59976</th>\n",
       "      <td>-0.820377</td>\n",
       "      <td>-0.270608</td>\n",
       "      <td>-0.274254</td>\n",
       "      <td>-0.28344</td>\n",
       "      <td>-1.264172</td>\n",
       "      <td>-0.934785</td>\n",
       "      <td>-1.237946</td>\n",
       "      <td>0.782665</td>\n",
       "      <td>-0.947308</td>\n",
       "      <td>-0.356335</td>\n",
       "      <td>-0.07481</td>\n",
       "      <td>-0.560734</td>\n",
       "      <td>-0.724925</td>\n",
       "      <td>-0.616207</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>-1.67904</td>\n",
       "      <td>-0.382359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50392</td>\n",
       "      <td>-0.135343</td>\n",
       "      <td>-0.180383</td>\n",
       "      <td>0.038404</td>\n",
       "      <td>0.308128</td>\n",
       "      <td>-0.089766</td>\n",
       "      <td>-0.123259</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>-0.089427</td>\n",
       "      <td>-0.123259</td>\n",
       "      <td>0.038169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          STYLE      ROOF  EXTFINISH  BASEMENT   STORIES  TOTALROOMS  \\\n",
       "59976 -0.820377 -0.270608  -0.274254  -0.28344 -1.264172   -0.934785   \n",
       "\n",
       "       BEDROOMS  FULLBATHS  HALFBATHS  FINISHEDLIVINGAREA  ZIPCODE  YEARSOLD  \\\n",
       "59976 -1.237946   0.782665  -0.947308           -0.356335 -0.07481 -0.560734   \n",
       "\n",
       "       SALEDATE  PREVSALEPRICE    COUNTS  Condition     GRADE  CDU  LOTAREA  \\\n",
       "59976 -0.724925      -0.616207  0.983908   -1.67904 -0.382359  3.0  0.50392   \n",
       "\n",
       "       COUNTYTOTAL  COUNTYBUILDING  COUNTYLAND      HOOD  FAIRMARKETTOTAL  \\\n",
       "59976    -0.135343       -0.180383    0.038404  0.308128        -0.089766   \n",
       "\n",
       "       FAIRMARKETBUILDING  FAIRMARKETLAND  LOCALTOTAL  LOCALBUILDING  \\\n",
       "59976           -0.123259        0.036367   -0.089427      -0.123259   \n",
       "\n",
       "       LOCALLAND  \n",
       "59976   0.038169  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "We will build some models on our data and see which model performs the best. The following models will be evaluated:\n",
    "\n",
    "* XGBoost\n",
    "* RandomForest\n",
    "* KNearest Neighbors\n",
    "* Support Vector Machine\n",
    "* Gradient Boosted Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We are choosing to evaluate our performance using the `Mean Squared Logarithmic Error` instead of more traditional methods (such as RMSE). This is because the MSLE is more **robust against outliers**, and it **penalizes under-estimation more than over-estimations**, which should be the preference to someone hoping to maximize their profits off of their home.\n",
    "\n",
    "Home Sales are skewed to the right, with a few really expensive homes. The MSLE will help protect against those outliers, and help us determine which model and parameters to use.\n",
    "\n",
    "We are using the MSLE metric for the following:\n",
    "* Model Selection\n",
    "* Hyper Parameter Tuning\n",
    "* Testing\n",
    "\n",
    "We then compare our results against Zillow using their customer facing metrics. There is more on this later in the Notebook.\n",
    "\n",
    "References:\n",
    "* https://www.kaggle.com/c/zillow-prize-1/discussion/33899\n",
    "* https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-squared-logarithmic-error-(msle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Function\n",
    "Here we will define a function that accepts a model, parameters, and data. This model will build the model and test it.\n",
    "\n",
    "This function will be useful for testing all of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import time\n",
    "\n",
    "def test_model(model, params, model_name, X_train, y_train, X_test, Y_test):\n",
    "    \"\"\"Trains model, and evaluates it.\n",
    "        PARAMS:\n",
    "            model_choice - SKLearn Model: Model to be trained\n",
    "            params - dictionary: Dictionary of parameters to feed the model\n",
    "            X_train - DataFrame: Training Data, Features\n",
    "            y_train - DataFrame: Training Data, Targets\n",
    "            X_test - DataFrame: Testing Data, Features\n",
    "            y_test - DataFrame: Testing Data, Targets\n",
    "        \n",
    "        RETURNS:\n",
    "            Mean Squared Log Error, Tree Explainer, Model Name - tuple(float, Explainer, String): Accuracy for specified model and parameters. \n",
    "    \"\"\"\n",
    "    print(\"Begin \", model_name)\n",
    "    start = time.time()\n",
    "\n",
    "    # Run model and get predictions and Mean Squared Log Error\n",
    "    clf = model(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = clf.predict(X_test)\n",
    "    if predictions.min() < 10000:\n",
    "        print(\"\\t- [WARNING] - Out of bounds prediction... Replacing with 10,000\")\n",
    "        predictions[predictions < 0] = 10000\n",
    "    \n",
    "    msle = mean_squared_log_error(Y_test, predictions)\n",
    "    rmse = mean_squared_error(Y_test, predictions)**0.5\n",
    "    r2 = r2_score(Y_test, predictions)\n",
    "    \n",
    "    print(f\"\\t- MSLE: \", msle)\n",
    "    print(f\"\\t- RMSE: \", rmse)\n",
    "    print(f\"\\t- R^2: \", r2)\n",
    "    \n",
    "    print(\"\\t- Time Elapsed: \", time.time() - start)\n",
    "    \n",
    "    return (msle, clf, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Models\n",
    "We will run all of the following models through the testing function:\n",
    "* XGBoost\n",
    "* RandomForest\n",
    "* KNearest Neighbors\n",
    "* Support Vector Machine\n",
    "* Gradient Boosted Decision Tree\n",
    "\n",
    "Each of these models will be trained on the `Training Set` and evaluated on the `Validation Set`. The model that performs the best on the evaluation set (lowest `Mean Squared Log Error`), will be promoted to the next phase of model tuning (Hyper Parameter Tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin  XGBoost\n",
      "\t- [WARNING] - Out of bounds prediction... Replacing with 10,000\n",
      "\t- MSLE:  0.056294345322220454\n",
      "\t- RMSE:  28799.343399305188\n",
      "\t- R^2:  0.9421110808232729\n",
      "\t- Time Elapsed:  4.178821086883545\n",
      "Begin  Random Forest\n",
      "\t- MSLE:  0.04831768358850574\n",
      "\t- RMSE:  27793.990584216284\n",
      "\t- R^2:  0.9460822102911227\n",
      "\t- Time Elapsed:  99.60424828529358\n",
      "Begin  KNeighbors\n",
      "\t- MSLE:  0.0767894725378354\n",
      "\t- RMSE:  35617.378173478544\n",
      "\t- R^2:  0.9114570140967407\n",
      "\t- Time Elapsed:  42.99288845062256\n",
      "Begin  Support Vector Machine\n",
      "\t- [WARNING] - Out of bounds prediction... Replacing with 10,000\n",
      "\t- MSLE:  0.1099224094225798\n",
      "\t- RMSE:  44734.3511324703\n",
      "\t- R^2:  0.860326970495376\n",
      "\t- Time Elapsed:  0.15994691848754883\n",
      "Begin  GradientBoostingRegressor\n",
      "\t- [WARNING] - Out of bounds prediction... Replacing with 10,000\n",
      "\t- MSLE:  0.05770739901680598\n",
      "\t- RMSE:  29111.758759165634\n",
      "\t- R^2:  0.940848310180744\n",
      "\t- Time Elapsed:  29.151199102401733\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "knc_params = {}\n",
    "svr_params = {}\n",
    "gbr_params = {}\n",
    "xgb_params = {'objective':'reg:squarederror'}\n",
    "rf_params = {}\n",
    "\n",
    "models_to_test = [\n",
    "    (xgb.XGBRegressor, xgb_params, \"XGBoost\"),\n",
    "    (RandomForestRegressor, rf_params, \"Random Forest\"),\n",
    "    (KNeighborsRegressor, knc_params, \"KNeighbors\"),\n",
    "    (LinearSVR, svr_params, \"Support Vector Machine\"),\n",
    "    (GradientBoostingRegressor, gbr_params, \"GradientBoostingRegressor\")\n",
    "]\n",
    "\n",
    "results = []\n",
    "for model in models_to_test:\n",
    "    results += [test_model(model[0], model[1], model[2], X_train, y_train, X_val, y_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model:  Random Forest\n"
     ]
    }
   ],
   "source": [
    "# Sort results by the best accuracy.\n",
    "results.sort(key = lambda x: x[0], reverse=False)\n",
    "\n",
    "print(\"Best Model: \", results[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning\n",
    "`Random Forest` has the best performance.\n",
    "\n",
    "We will now run a Grid Search on it to see which parameters might be most effective. We have already run a Randomized Grid Search (in the past) to see how we should narrow down our parameter space. \n",
    "\n",
    "    > NOTE: We are choosing to use a smaller `max_depth`. We do this so it can act as a regularization term. We may not get better results (than a higher max_depth), but we will get a more general model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin  RandomForest\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 27.3min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed: 34.7min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 42.0min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed: 51.0min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed: 58.9min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed: 67.8min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed: 82.6min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed: 101.8min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 119.3min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed: 140.5min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 159.0min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed: 178.8min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed: 200.5min\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed: 225.0min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed: 248.3min\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed: 271.9min\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed: 295.7min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 324.9min\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed: 351.7min\n",
      "[Parallel(n_jobs=-1)]: Done 405 tasks      | elapsed: 379.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Best Score:  -0.08667658762376557\n",
      "\t- Time Elapsed:  24085.26882505417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 432 out of 432 | elapsed: 401.4min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def grid_search(clf, params, model_name, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Run Grid Search on a model\"\"\"\n",
    "    print(\"Begin \", model_name)\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    clf = GridSearchCV(clf(), params, refit=False, scoring='neg_mean_squared_log_error', cv=3, n_jobs=-1, verbose=10)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"\\t- Best Score: \", clf.best_score_)\n",
    "    print(\"\\t- Time Elapsed: \", time.time() - start)\n",
    "    \n",
    "    return (clf.best_score_, clf, model_name)\n",
    "\n",
    "# Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
    "params_rf = {\n",
    "    'bootstrap': [True], # Whether to bootstrap samples when building tress.\n",
    "    'max_depth': [40,50,60], # Max depth of tree. NOTE: Larger number increases risk for overfitting.\n",
    "    'max_features': ['auto'], # Num features to consider when looking for the best split.\n",
    "    'min_samples_leaf': [3,4], # Minimum num of samples required to be at a leaf node.\n",
    "    'min_samples_split': [4,5,6], # Minimum num of samples required to split an internal node\n",
    "    'n_estimators': [700,800] # The number of trees in the forest\n",
    "}\n",
    "\n",
    "models_to_tune = [\n",
    "    (RandomForestRegressor, params_rf, \"RandomForest\")\n",
    "]\n",
    "\n",
    "tuned_results = []\n",
    "for model in models_to_tune:\n",
    "    tuned_results += [grid_search(model[0], model[1], model[2], X_train, y_train, X_val, y_val)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Parameters\n",
    "We can view the best parameters by extracting `cv_results_`. This will allow us to see how the best parameters compared to the other parameters.\n",
    "\n",
    "During the Hyper Parameter Tuning process, this was useful in order to narrow the search space down. For example, We saw consistently worse results during the following:\n",
    "* bootstrap : False\n",
    "* max_features : sq_rt\n",
    "\n",
    "Armed with this knowledge, we were able to reduce the number of parameters we need to search over, so GridSearch might be more efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>720.437881</td>\n",
       "      <td>5.738681</td>\n",
       "      <td>35.799942</td>\n",
       "      <td>5.115000</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>800</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 30, 'max_feat...</td>\n",
       "      <td>-0.087288</td>\n",
       "      <td>-0.087469</td>\n",
       "      <td>-0.085272</td>\n",
       "      <td>-0.086677</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>476.496650</td>\n",
       "      <td>3.103757</td>\n",
       "      <td>17.533694</td>\n",
       "      <td>1.087101</td>\n",
       "      <td>True</td>\n",
       "      <td>70</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 70, 'max_feat...</td>\n",
       "      <td>-0.087397</td>\n",
       "      <td>-0.087305</td>\n",
       "      <td>-0.085335</td>\n",
       "      <td>-0.086679</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>525.941559</td>\n",
       "      <td>4.068096</td>\n",
       "      <td>13.725002</td>\n",
       "      <td>0.497933</td>\n",
       "      <td>True</td>\n",
       "      <td>70</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 70, 'max_feat...</td>\n",
       "      <td>-0.087287</td>\n",
       "      <td>-0.087509</td>\n",
       "      <td>-0.085269</td>\n",
       "      <td>-0.086688</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>631.958763</td>\n",
       "      <td>4.763423</td>\n",
       "      <td>27.796708</td>\n",
       "      <td>3.998328</td>\n",
       "      <td>True</td>\n",
       "      <td>70</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>800</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 70, 'max_feat...</td>\n",
       "      <td>-0.087358</td>\n",
       "      <td>-0.087355</td>\n",
       "      <td>-0.085363</td>\n",
       "      <td>-0.086692</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>528.396451</td>\n",
       "      <td>2.014544</td>\n",
       "      <td>14.378223</td>\n",
       "      <td>2.534722</td>\n",
       "      <td>True</td>\n",
       "      <td>50</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 50, 'max_feat...</td>\n",
       "      <td>-0.087232</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.085373</td>\n",
       "      <td>-0.086698</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "41      720.437881      5.738681        35.799942        5.115000   \n",
       "124     476.496650      3.103757        17.533694        1.087101   \n",
       "112     525.941559      4.068096        13.725002        0.497933   \n",
       "125     631.958763      4.763423        27.796708        3.998328   \n",
       "76      528.396451      2.014544        14.378223        2.534722   \n",
       "\n",
       "    param_bootstrap param_max_depth param_max_features param_min_samples_leaf  \\\n",
       "41             True              30               auto                      1   \n",
       "124            True              70                0.9                      1   \n",
       "112            True              70               auto                      1   \n",
       "125            True              70                0.9                      1   \n",
       "76             True              50               auto                      1   \n",
       "\n",
       "    param_min_samples_split param_n_estimators  \\\n",
       "41                        6                800   \n",
       "124                       6                600   \n",
       "112                       6                600   \n",
       "125                       6                800   \n",
       "76                        6                600   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "41   {'bootstrap': True, 'max_depth': 30, 'max_feat...          -0.087288   \n",
       "124  {'bootstrap': True, 'max_depth': 70, 'max_feat...          -0.087397   \n",
       "112  {'bootstrap': True, 'max_depth': 70, 'max_feat...          -0.087287   \n",
       "125  {'bootstrap': True, 'max_depth': 70, 'max_feat...          -0.087358   \n",
       "76   {'bootstrap': True, 'max_depth': 50, 'max_feat...          -0.087232   \n",
       "\n",
       "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "41           -0.087469          -0.085272        -0.086677        0.000996   \n",
       "124          -0.087305          -0.085335        -0.086679        0.000951   \n",
       "112          -0.087509          -0.085269        -0.086688        0.001008   \n",
       "125          -0.087355          -0.085363        -0.086692        0.000940   \n",
       "76           -0.087490          -0.085373        -0.086698        0.000943   \n",
       "\n",
       "     rank_test_score  \n",
       "41                 1  \n",
       "124                2  \n",
       "112                3  \n",
       "125                4  \n",
       "76                 5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab parameter results\n",
    "param_results = pd.DataFrame(tuned_results[0][1].cv_results_).sort_values('rank_test_score')\n",
    "\n",
    "# Write Parameters to CSV\n",
    "import os\n",
    "# if file does not exist write header \n",
    "if not os.path.isfile('random_forest_params.csv'):\n",
    "    param_results.to_csv('random_forest_params.csv', header=True)\n",
    "else: # else it exists so append without writing the header\n",
    "    param_results.to_csv('random_forest_params.csv', mode='a', header=False)\n",
    "\n",
    "param_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "\n",
    "We will evaluate the performance of the `RandomForestRegressor` model on the \n",
    "* Training Set\n",
    "* Validation Set\n",
    "* Testing Set\n",
    "\n",
    "Understanding how the results varies within each of the data sets will help us understand how well the model is generalizing to new data. We expect to see a similar results across all data sets.\n",
    "\n",
    "> NOTE: We will only using the results on the `testing` for determining to accept or decline our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed:  952.3487150669098\n",
      "TRAINING\n",
      "\tMean Squared Log Error:  0.018780335983851128\n",
      "\tRoot Mean Squared Error:  15860.462456299621\n",
      "\tR2-Score:  0.9824367769406057\n",
      "VALIDATION\n",
      "\tMean Squared Log Error:  0.047469299317068205\n",
      "\tRoot Mean Squared Error:  27565.683532245475\n",
      "\tR2-Score:  0.9469643616746305\n",
      "TESTING\n",
      "\tMean Squared Log Error:  0.05322638922223281\n",
      "\tRoot Mean Squared Error:  29578.143670601694\n",
      "\tR2-Score:  0.940356917111337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "best_clf = RandomForestRegressor(**tuned_results[0][1].best_params_).fit(X_train, y_train)\n",
    "\n",
    "print(\"Time Elapsed: \", time.time() - start)\n",
    "\n",
    "predictions = best_clf.predict(X_train)\n",
    "msle = mean_squared_log_error(y_train, predictions)\n",
    "rmse = mean_squared_error(y_train, predictions)**0.5\n",
    "r2 = r2_score(y_train, predictions)\n",
    "\n",
    "print(\"TRAINING\")\n",
    "print(\"\\tMean Squared Log Error: \", msle)\n",
    "print(\"\\tRoot Mean Squared Error: \", rmse)\n",
    "print(\"\\tR2-Score: \", r2)\n",
    "\n",
    "predictions = best_clf.predict(X_val)\n",
    "msle = mean_squared_log_error(y_val, predictions)\n",
    "rmse = mean_squared_error(y_val, predictions)**0.5\n",
    "r2 = r2_score(y_val, predictions)\n",
    "\n",
    "print(\"VALIDATION\")\n",
    "print(\"\\tMean Squared Log Error: \", msle)\n",
    "print(\"\\tRoot Mean Squared Error: \", rmse)\n",
    "print(\"\\tR2-Score: \", r2)\n",
    "\n",
    "test_predictions = best_clf.predict(X_test)\n",
    "msle = mean_squared_log_error(y_test, test_predictions)\n",
    "rmse = mean_squared_error(y_test, test_predictions)**0.5\n",
    "r2 = r2_score(y_test, test_predictions)\n",
    "\n",
    "print(\"TESTING\")\n",
    "print(\"\\tMean Squared Log Error: \", msle)\n",
    "print(\"\\tRoot Mean Squared Error: \", rmse)\n",
    "print(\"\\tR2-Score: \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zillow's Zestimate\n",
    "Zillow presents their results via a table that displays the following:\n",
    "* Median Error\n",
    "* Homes With ZESTIMATES\n",
    "* Within 5% of Sale Price\n",
    "* Within 10% of Sale Price\n",
    "* Within 20% of Sale Price\n",
    "\n",
    "We will develop the same metrics from our results and compare them to Zillows results on `Pittsburgh PA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# Concatentate Predictions with Actual\n",
    "comparison = pd.concat([pd.Series(test_predictions), y_test], axis=1)\n",
    "comparison = comparison.rename(columns={0:'PREDICTION'})\n",
    "\n",
    "# Calculate `Percent Error`\n",
    "## |(Prediction - SalePrice) / SalePrice|\n",
    "comparison['PERCENT ERROR'] = abs((comparison['PREDICTION'] - comparison['SALEPRICE']) / comparison['SALEPRICE'])\n",
    "\n",
    "# Write to CSV\n",
    "comparison.to_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREDICTION</th>\n",
       "      <th>SALEPRICE</th>\n",
       "      <th>PERCENT ERROR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94372.340933</td>\n",
       "      <td>97000.0</td>\n",
       "      <td>0.027089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135083.987621</td>\n",
       "      <td>125500.0</td>\n",
       "      <td>0.076366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103085.690310</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>0.334931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137102.807384</td>\n",
       "      <td>140500.0</td>\n",
       "      <td>0.024179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35542.178252</td>\n",
       "      <td>36500.0</td>\n",
       "      <td>0.026242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PREDICTION  SALEPRICE  PERCENT ERROR\n",
       "0   94372.340933    97000.0       0.027089\n",
       "1  135083.987621   125500.0       0.076366\n",
       "2  103085.690310   155000.0       0.334931\n",
       "3  137102.807384   140500.0       0.024179\n",
       "4   35542.178252    36500.0       0.026242"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>METROPOLITAN AREA</th>\n",
       "      <th>MEDIAN ERROR</th>\n",
       "      <th>HOMES WITH ESTIMATE</th>\n",
       "      <th>WITHIN 5% OF SALEPRICE</th>\n",
       "      <th>WITHIN 10% OF SALEPRICE</th>\n",
       "      <th>WITHIN 20% OF SALEPRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Our Results</th>\n",
       "      <td>Pittsburgh, PA</td>\n",
       "      <td>8.24032</td>\n",
       "      <td>13628</td>\n",
       "      <td>33.900792</td>\n",
       "      <td>56.596713</td>\n",
       "      <td>79.123863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zillow</th>\n",
       "      <td>Pittsburgh, PA</td>\n",
       "      <td>2.50000</td>\n",
       "      <td>10900</td>\n",
       "      <td>77.600000</td>\n",
       "      <td>93.200000</td>\n",
       "      <td>98.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            METROPOLITAN AREA  MEDIAN ERROR  HOMES WITH ESTIMATE  \\\n",
       "Our Results    Pittsburgh, PA       8.24032                13628   \n",
       "Zillow         Pittsburgh, PA       2.50000                10900   \n",
       "\n",
       "             WITHIN 5% OF SALEPRICE  WITHIN 10% OF SALEPRICE  \\\n",
       "Our Results               33.900792                56.596713   \n",
       "Zillow                    77.600000                93.200000   \n",
       "\n",
       "             WITHIN 20% OF SALEPRICE  \n",
       "Our Results                79.123863  \n",
       "Zillow                     98.400000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain Metrics to create table.\n",
    "\n",
    "area = 'Pittsburgh, PA'\n",
    "median_error = comparison['PERCENT ERROR'].median() * 100\n",
    "total_estimates = comparison.shape[0]\n",
    "five_percent = comparison[comparison['PERCENT ERROR'] <= 0.05].shape[0] / comparison.shape[0] * 100\n",
    "ten_percent = comparison[comparison['PERCENT ERROR'] <= 0.10].shape[0] / comparison.shape[0] * 100\n",
    "twenty_percent = comparison[comparison['PERCENT ERROR'] <= 0.20].shape[0] / comparison.shape[0] * 100\n",
    "\n",
    "column_names = ['METROPOLITAN AREA', 'MEDIAN ERROR', 'HOMES WITH ESTIMATE', 'WITHIN 5% OF SALEPRICE', 'WITHIN 10% OF SALEPRICE', 'WITHIN 20% OF SALEPRICE']\n",
    "\n",
    "results_lst = [area, median_error, total_estimates, five_percent, ten_percent, twenty_percent]\n",
    "zillow_lst = ['Pittsburgh, PA', 2.5, 10900, 77.6, 93.2, 98.4]\n",
    "\n",
    "results = pd.DataFrame([results_lst, zillow_lst], index=['Our Results', 'Zillow'], columns=column_names)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance:\n",
    "\n",
    "### Random Forest Feature Importance\n",
    "Random Forest has a built in feature importance, which will tell us how important each feature is. However, this does not tell us what kind of values the features should have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = X.columns.tolist()\n",
    "importances = best_clf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "We tested the following models:\n",
    "* XGBoost\n",
    "* RandomForest\n",
    "* KNearest Neighbors\n",
    "* Support Vector Machine\n",
    "* Gradient Boosted Decision Tree\n",
    "\n",
    "The best performing model was `RandomForest`. Once we found the best performing model, we implemented a `Grid Search` which aimed to exhaustively explore a specified grid and find the best parameters. Once we tuned our parameters, we tested our predictions on our Training, Validation, and Testing set.\n",
    "\n",
    "Our testing set had a RMSE of `4780.84`. This indicates that we still have a lot of room for improvements, so we might want to attempt a different approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
