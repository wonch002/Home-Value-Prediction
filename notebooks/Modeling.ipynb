{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Now that we have explored our data, and cleaned it up into an acceptable format, we are ready to run some modeling techniques on it. We will begin by building multiple generic models on the data set to see how well it performs. After this, we will build a Neural Network to see if we can improve the performance from the baseline models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset\n",
    "\n",
    "This dataset is already cleaned up and preprocessed. It is expected that this dataset has the following columns:\n",
    "* SALEPRICE\n",
    "* PROPERTYZIP\n",
    "\n",
    "> NOTE/TODO: Currently, we don't do anything with the PROPERTYZIP. We plan to build a model for each zipcode, but that is pending our preliminary results (to see if we need to even attempt such a thing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "data = pd.read_csv('output_total_df.csv')\n",
    "\n",
    "# Renaming columns to not include brackets, spaces, or commas\n",
    "column_mapping = {}\n",
    "for col in list(data.columns):\n",
    "\n",
    "    new_col = col.replace(']', ')')\n",
    "    new_col = new_col.replace('[', '(')\n",
    "    new_col = new_col.replace(', ', '-')\n",
    "    new_col = new_col.replace(' ', '')\n",
    "    column_mapping[col] = new_col\n",
    "\n",
    "data = data.rename(columns=column_mapping)\n",
    "\n",
    "# Drop Nulls\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed:0</th>\n",
       "      <th>STYLE</th>\n",
       "      <th>ROOF</th>\n",
       "      <th>EXTFINISH</th>\n",
       "      <th>BASEMENT</th>\n",
       "      <th>STORIES</th>\n",
       "      <th>TOTALROOMS</th>\n",
       "      <th>BEDROOMS</th>\n",
       "      <th>FULLBATHS</th>\n",
       "      <th>HALFBATHS</th>\n",
       "      <th>FINISHEDLIVINGAREA</th>\n",
       "      <th>ZIPCODE</th>\n",
       "      <th>YEARSOLD</th>\n",
       "      <th>SALEDATE</th>\n",
       "      <th>SALEMONTH</th>\n",
       "      <th>PREVSALEPRICE</th>\n",
       "      <th>COUNTS</th>\n",
       "      <th>Condition</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>CDU</th>\n",
       "      <th>LOTAREA</th>\n",
       "      <th>COUNTYTOTAL</th>\n",
       "      <th>COUNTYBUILDING</th>\n",
       "      <th>COUNTYLAND</th>\n",
       "      <th>HOOD</th>\n",
       "      <th>FAIRMARKETTOTAL</th>\n",
       "      <th>FAIRMARKETBUILDING</th>\n",
       "      <th>FAIRMARKETLAND</th>\n",
       "      <th>LOCALTOTAL</th>\n",
       "      <th>LOCALBUILDING</th>\n",
       "      <th>LOCALLAND</th>\n",
       "      <th>SALEPRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1.14236</td>\n",
       "      <td>0.60914</td>\n",
       "      <td>1.434605</td>\n",
       "      <td>4.059843</td>\n",
       "      <td>-1.264172</td>\n",
       "      <td>-2.140282</td>\n",
       "      <td>-2.394149</td>\n",
       "      <td>-0.763327</td>\n",
       "      <td>0.796003</td>\n",
       "      <td>-0.529069</td>\n",
       "      <td>0.66981</td>\n",
       "      <td>-1.831834</td>\n",
       "      <td>-1.190751</td>\n",
       "      <td>-0.869912</td>\n",
       "      <td>2.228069</td>\n",
       "      <td>0.856257</td>\n",
       "      <td>0.057441</td>\n",
       "      <td>-4.048448</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.308887</td>\n",
       "      <td>1.501219</td>\n",
       "      <td>2.260656</td>\n",
       "      <td>-1.177967</td>\n",
       "      <td>-0.269532</td>\n",
       "      <td>1.364566</td>\n",
       "      <td>2.086445</td>\n",
       "      <td>-1.173908</td>\n",
       "      <td>1.366649</td>\n",
       "      <td>2.086445</td>\n",
       "      <td>-1.178272</td>\n",
       "      <td>394000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>1.14236</td>\n",
       "      <td>0.60914</td>\n",
       "      <td>1.434605</td>\n",
       "      <td>4.059843</td>\n",
       "      <td>-1.264172</td>\n",
       "      <td>-1.537534</td>\n",
       "      <td>-1.237946</td>\n",
       "      <td>0.782665</td>\n",
       "      <td>-0.947308</td>\n",
       "      <td>-0.296914</td>\n",
       "      <td>0.66981</td>\n",
       "      <td>-1.831834</td>\n",
       "      <td>-0.788467</td>\n",
       "      <td>0.741401</td>\n",
       "      <td>-0.616165</td>\n",
       "      <td>1.198754</td>\n",
       "      <td>0.057441</td>\n",
       "      <td>-4.048448</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.308887</td>\n",
       "      <td>2.326670</td>\n",
       "      <td>3.279850</td>\n",
       "      <td>-1.177967</td>\n",
       "      <td>-0.269532</td>\n",
       "      <td>2.179001</td>\n",
       "      <td>3.091708</td>\n",
       "      <td>-1.173908</td>\n",
       "      <td>2.182061</td>\n",
       "      <td>3.091708</td>\n",
       "      <td>-1.178272</td>\n",
       "      <td>400000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>1.14236</td>\n",
       "      <td>0.60914</td>\n",
       "      <td>1.434605</td>\n",
       "      <td>4.059843</td>\n",
       "      <td>-1.264172</td>\n",
       "      <td>-2.140282</td>\n",
       "      <td>-2.394149</td>\n",
       "      <td>-0.763327</td>\n",
       "      <td>0.796003</td>\n",
       "      <td>-1.134329</td>\n",
       "      <td>0.66981</td>\n",
       "      <td>-1.831834</td>\n",
       "      <td>-1.238672</td>\n",
       "      <td>0.419138</td>\n",
       "      <td>1.099104</td>\n",
       "      <td>1.536139</td>\n",
       "      <td>0.057441</td>\n",
       "      <td>-4.048448</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.308887</td>\n",
       "      <td>1.138164</td>\n",
       "      <td>1.812389</td>\n",
       "      <td>-1.177967</td>\n",
       "      <td>-0.269532</td>\n",
       "      <td>1.006357</td>\n",
       "      <td>1.644306</td>\n",
       "      <td>-1.173908</td>\n",
       "      <td>1.008011</td>\n",
       "      <td>1.644306</td>\n",
       "      <td>-1.178272</td>\n",
       "      <td>302000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126</td>\n",
       "      <td>1.14236</td>\n",
       "      <td>0.60914</td>\n",
       "      <td>1.434605</td>\n",
       "      <td>4.059843</td>\n",
       "      <td>-1.264172</td>\n",
       "      <td>-2.140282</td>\n",
       "      <td>-2.394149</td>\n",
       "      <td>0.782665</td>\n",
       "      <td>-0.947308</td>\n",
       "      <td>-0.516632</td>\n",
       "      <td>0.66981</td>\n",
       "      <td>-1.831834</td>\n",
       "      <td>-0.917097</td>\n",
       "      <td>0.096875</td>\n",
       "      <td>3.201099</td>\n",
       "      <td>0.314396</td>\n",
       "      <td>0.057441</td>\n",
       "      <td>-4.048448</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.308887</td>\n",
       "      <td>2.085537</td>\n",
       "      <td>2.982120</td>\n",
       "      <td>-1.177967</td>\n",
       "      <td>-0.269532</td>\n",
       "      <td>2.101478</td>\n",
       "      <td>2.996021</td>\n",
       "      <td>-1.173908</td>\n",
       "      <td>2.104446</td>\n",
       "      <td>2.996021</td>\n",
       "      <td>-1.178272</td>\n",
       "      <td>425000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127</td>\n",
       "      <td>1.14236</td>\n",
       "      <td>0.60914</td>\n",
       "      <td>1.434605</td>\n",
       "      <td>4.059843</td>\n",
       "      <td>-1.264172</td>\n",
       "      <td>-1.537534</td>\n",
       "      <td>-1.237946</td>\n",
       "      <td>0.782665</td>\n",
       "      <td>-0.947308</td>\n",
       "      <td>-0.584344</td>\n",
       "      <td>0.66981</td>\n",
       "      <td>-1.831834</td>\n",
       "      <td>-0.784684</td>\n",
       "      <td>0.419138</td>\n",
       "      <td>-0.601270</td>\n",
       "      <td>2.088224</td>\n",
       "      <td>0.057441</td>\n",
       "      <td>-4.048448</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.308887</td>\n",
       "      <td>1.432581</td>\n",
       "      <td>2.175909</td>\n",
       "      <td>-1.177967</td>\n",
       "      <td>-0.269532</td>\n",
       "      <td>1.457237</td>\n",
       "      <td>2.200830</td>\n",
       "      <td>-1.173908</td>\n",
       "      <td>1.459431</td>\n",
       "      <td>2.200830</td>\n",
       "      <td>-1.178272</td>\n",
       "      <td>300000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed:0    STYLE     ROOF  EXTFINISH  BASEMENT   STORIES  TOTALROOMS  \\\n",
       "0         11  1.14236  0.60914   1.434605  4.059843 -1.264172   -2.140282   \n",
       "1         75  1.14236  0.60914   1.434605  4.059843 -1.264172   -1.537534   \n",
       "2         82  1.14236  0.60914   1.434605  4.059843 -1.264172   -2.140282   \n",
       "3        126  1.14236  0.60914   1.434605  4.059843 -1.264172   -2.140282   \n",
       "4        127  1.14236  0.60914   1.434605  4.059843 -1.264172   -1.537534   \n",
       "\n",
       "   BEDROOMS  FULLBATHS  HALFBATHS  FINISHEDLIVINGAREA  ZIPCODE  YEARSOLD  \\\n",
       "0 -2.394149  -0.763327   0.796003           -0.529069  0.66981 -1.831834   \n",
       "1 -1.237946   0.782665  -0.947308           -0.296914  0.66981 -1.831834   \n",
       "2 -2.394149  -0.763327   0.796003           -1.134329  0.66981 -1.831834   \n",
       "3 -2.394149   0.782665  -0.947308           -0.516632  0.66981 -1.831834   \n",
       "4 -1.237946   0.782665  -0.947308           -0.584344  0.66981 -1.831834   \n",
       "\n",
       "   SALEDATE  SALEMONTH  PREVSALEPRICE    COUNTS  Condition     GRADE  CDU  \\\n",
       "0 -1.190751  -0.869912       2.228069  0.856257   0.057441 -4.048448  4.0   \n",
       "1 -0.788467   0.741401      -0.616165  1.198754   0.057441 -4.048448  4.0   \n",
       "2 -1.238672   0.419138       1.099104  1.536139   0.057441 -4.048448  4.0   \n",
       "3 -0.917097   0.096875       3.201099  0.314396   0.057441 -4.048448  4.0   \n",
       "4 -0.784684   0.419138      -0.601270  2.088224   0.057441 -4.048448  4.0   \n",
       "\n",
       "    LOTAREA  COUNTYTOTAL  COUNTYBUILDING  COUNTYLAND      HOOD  \\\n",
       "0 -0.308887     1.501219        2.260656   -1.177967 -0.269532   \n",
       "1 -0.308887     2.326670        3.279850   -1.177967 -0.269532   \n",
       "2 -0.308887     1.138164        1.812389   -1.177967 -0.269532   \n",
       "3 -0.308887     2.085537        2.982120   -1.177967 -0.269532   \n",
       "4 -0.308887     1.432581        2.175909   -1.177967 -0.269532   \n",
       "\n",
       "   FAIRMARKETTOTAL  FAIRMARKETBUILDING  FAIRMARKETLAND  LOCALTOTAL  \\\n",
       "0         1.364566            2.086445       -1.173908    1.366649   \n",
       "1         2.179001            3.091708       -1.173908    2.182061   \n",
       "2         1.006357            1.644306       -1.173908    1.008011   \n",
       "3         2.101478            2.996021       -1.173908    2.104446   \n",
       "4         1.457237            2.200830       -1.173908    1.459431   \n",
       "\n",
       "   LOCALBUILDING  LOCALLAND  SALEPRICE  \n",
       "0       2.086445  -1.178272   394000.0  \n",
       "1       3.091708  -1.178272   400000.0  \n",
       "2       1.644306  -1.178272   302000.0  \n",
       "3       2.996021  -1.178272   425000.0  \n",
       "4       2.200830  -1.178272   300000.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Validation/Test Split\n",
    "\n",
    "We will split our dataset into three sets:\n",
    "* Training - (77%)\n",
    "* Validation - (16.5%)\n",
    "* Testing - (16.5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape:  (55336, 30)\n",
      "Validation Shape:  (13628, 30)\n",
      "Testing Shape:  (13628, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop(['Unnamed:0', 'SALEPRICE'], axis=1)\n",
    "Y = data['SALEPRICE']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle=True, random_state=100)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, shuffle=True, random_state=100)\n",
    "\n",
    "print(\"Training Shape: \", X_train.shape)\n",
    "print(\"Validation Shape: \", X_val.shape)\n",
    "print(\"Testing Shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STYLE</th>\n",
       "      <th>ROOF</th>\n",
       "      <th>EXTFINISH</th>\n",
       "      <th>BASEMENT</th>\n",
       "      <th>STORIES</th>\n",
       "      <th>TOTALROOMS</th>\n",
       "      <th>BEDROOMS</th>\n",
       "      <th>FULLBATHS</th>\n",
       "      <th>HALFBATHS</th>\n",
       "      <th>FINISHEDLIVINGAREA</th>\n",
       "      <th>ZIPCODE</th>\n",
       "      <th>YEARSOLD</th>\n",
       "      <th>SALEDATE</th>\n",
       "      <th>SALEMONTH</th>\n",
       "      <th>PREVSALEPRICE</th>\n",
       "      <th>COUNTS</th>\n",
       "      <th>Condition</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>CDU</th>\n",
       "      <th>LOTAREA</th>\n",
       "      <th>COUNTYTOTAL</th>\n",
       "      <th>COUNTYBUILDING</th>\n",
       "      <th>COUNTYLAND</th>\n",
       "      <th>HOOD</th>\n",
       "      <th>FAIRMARKETTOTAL</th>\n",
       "      <th>FAIRMARKETBUILDING</th>\n",
       "      <th>FAIRMARKETLAND</th>\n",
       "      <th>LOCALTOTAL</th>\n",
       "      <th>LOCALBUILDING</th>\n",
       "      <th>LOCALLAND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59976</th>\n",
       "      <td>-0.820377</td>\n",
       "      <td>-0.270608</td>\n",
       "      <td>-0.274254</td>\n",
       "      <td>-0.28344</td>\n",
       "      <td>-1.264172</td>\n",
       "      <td>-0.934785</td>\n",
       "      <td>-1.237946</td>\n",
       "      <td>0.782665</td>\n",
       "      <td>-0.947308</td>\n",
       "      <td>-0.356335</td>\n",
       "      <td>-0.07475</td>\n",
       "      <td>-0.560836</td>\n",
       "      <td>-0.724993</td>\n",
       "      <td>-0.869912</td>\n",
       "      <td>-0.616173</td>\n",
       "      <td>0.984055</td>\n",
       "      <td>-1.679064</td>\n",
       "      <td>-0.382411</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.504021</td>\n",
       "      <td>-0.135235</td>\n",
       "      <td>-0.180281</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.308284</td>\n",
       "      <td>-0.089656</td>\n",
       "      <td>-0.123154</td>\n",
       "      <td>0.036462</td>\n",
       "      <td>-0.089316</td>\n",
       "      <td>-0.123154</td>\n",
       "      <td>0.038264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          STYLE      ROOF  EXTFINISH  BASEMENT   STORIES  TOTALROOMS  \\\n",
       "59976 -0.820377 -0.270608  -0.274254  -0.28344 -1.264172   -0.934785   \n",
       "\n",
       "       BEDROOMS  FULLBATHS  HALFBATHS  FINISHEDLIVINGAREA  ZIPCODE  YEARSOLD  \\\n",
       "59976 -1.237946   0.782665  -0.947308           -0.356335 -0.07475 -0.560836   \n",
       "\n",
       "       SALEDATE  SALEMONTH  PREVSALEPRICE    COUNTS  Condition     GRADE  CDU  \\\n",
       "59976 -0.724993  -0.869912      -0.616173  0.984055  -1.679064 -0.382411  3.0   \n",
       "\n",
       "        LOTAREA  COUNTYTOTAL  COUNTYBUILDING  COUNTYLAND      HOOD  \\\n",
       "59976  0.504021    -0.135235       -0.180281      0.0385  0.308284   \n",
       "\n",
       "       FAIRMARKETTOTAL  FAIRMARKETBUILDING  FAIRMARKETLAND  LOCALTOTAL  \\\n",
       "59976        -0.089656           -0.123154        0.036462   -0.089316   \n",
       "\n",
       "       LOCALBUILDING  LOCALLAND  \n",
       "59976      -0.123154   0.038264  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "We will build some models on our data and see which model performs the best. The following models will be evaluated:\n",
    "\n",
    "* XGBoost\n",
    "* RandomForest\n",
    "* KNearest Neighbors\n",
    "* Support Vector Machine\n",
    "* Gradient Boosted Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Function\n",
    "Here we will define a function that accepts a model, parameters, and data. This model will build the model and test it.\n",
    "\n",
    "This function will be useful for testing all of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import time\n",
    "\n",
    "def test_model(model, params, model_name, X_train, y_train, X_test, Y_test):\n",
    "    \"\"\"Trains model, and evaluates it.\n",
    "        PARAMS:\n",
    "            model_choice - SKLearn Model: Model to be trained\n",
    "            params - dictionary: Dictionary of parameters to feed the model\n",
    "            X_train - DataFrame: Training Data, Features\n",
    "            y_train - DataFrame: Training Data, Targets\n",
    "            X_test - DataFrame: Testing Data, Features\n",
    "            y_test - DataFrame: Testing Data, Targets\n",
    "        \n",
    "        RETURNS:\n",
    "            Mean Squared Log Error, Tree Explainer, Model Name - tuple(float, Explainer, String): Accuracy for specified model and parameters. \n",
    "    \"\"\"\n",
    "    print(\"Begin \", model_name)\n",
    "    start = time.time()\n",
    "\n",
    "    # Run model and get predictions and Mean Squared Log Error\n",
    "    clf = model(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = clf.predict(X_test)\n",
    "    if predictions.min() < 10000:\n",
    "        print(\"\\t- [WARNING] - Out of bounds prediction... Replacing with 10,000\")\n",
    "        predictions[predictions < 0] = 10000\n",
    "    \n",
    "    msle = mean_squared_log_error(Y_test, predictions)\n",
    "    rmse = mean_squared_error(Y_test, predictions)**0.5\n",
    "    r2 = r2_score(Y_test, predictions)\n",
    "    \n",
    "    print(f\"\\t- MSLE: \", msle)\n",
    "    print(f\"\\t- RMSE: \", rmse)\n",
    "    print(f\"\\t- R^2: \", r2)\n",
    "    \n",
    "    print(\"\\t- Time Elapsed: \", time.time() - start)\n",
    "    \n",
    "    return (msle, clf, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Models\n",
    "We will run all of the following models through the testing function:\n",
    "* XGBoost\n",
    "* RandomForest\n",
    "* KNearest Neighbors\n",
    "* Support Vector Machine\n",
    "* Gradient Boosted Decision Tree\n",
    "\n",
    "Each of these models will be trained on the `Training Set` and evaluated on the `Validation Set`. The model that performs the best on the evaluation set (lowest `Mean Squared Log Error`), will be promoted to the next phase of model tuning (Hyper Parameter Tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin  XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matthew Tate\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- [WARNING] - Out of bounds prediction... Replacing with 10,000\n",
      "\t- MSLE:  0.05623469648617925\n",
      "\t- RMSE:  28832.66980219651\n",
      "\t- R^2:  0.9419770259830489\n",
      "\t- Time Elapsed:  5.906584978103638\n",
      "Begin  Random Forest\n",
      "\t- MSLE:  0.04818997080637017\n",
      "\t- RMSE:  27866.560397262212\n",
      "\t- R^2:  0.9458002851712443\n",
      "\t- Time Elapsed:  67.4079041481018\n",
      "Begin  KNeighbors\n",
      "\t- MSLE:  0.07997512394461233\n",
      "\t- RMSE:  36342.78702005015\n",
      "\t- R^2:  0.9078136274043938\n",
      "\t- Time Elapsed:  26.35189437866211\n",
      "Begin  Support Vector Machine\n",
      "\t- [WARNING] - Out of bounds prediction... Replacing with 10,000\n",
      "\t- MSLE:  0.1100803927622709\n",
      "\t- RMSE:  44727.22823532089\n",
      "\t- R^2:  0.8603714462681604\n",
      "\t- Time Elapsed:  0.07252264022827148\n",
      "Begin  GradientBoostingRegressor\n",
      "\t- [WARNING] - Out of bounds prediction... Replacing with 10,000\n",
      "\t- MSLE:  0.05773086701278188\n",
      "\t- RMSE:  29144.16668986349\n",
      "\t- R^2:  0.9407165386242988\n",
      "\t- Time Elapsed:  15.921813011169434\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "knc_params = {}\n",
    "svr_params = {}\n",
    "gbr_params = {}\n",
    "xgb_params = {'objective':'reg:squarederror'}\n",
    "rf_params = {}\n",
    "\n",
    "models_to_test = [\n",
    "    (xgb.XGBRegressor, xgb_params, \"XGBoost\"),\n",
    "    (RandomForestRegressor, rf_params, \"Random Forest\"),\n",
    "    (KNeighborsRegressor, knc_params, \"KNeighbors\"),\n",
    "    (LinearSVR, svr_params, \"Support Vector Machine\"),\n",
    "    (GradientBoostingRegressor, gbr_params, \"GradientBoostingRegressor\")\n",
    "]\n",
    "\n",
    "results = []\n",
    "for model in models_to_test:\n",
    "    results += [test_model(model[0], model[1], model[2], X_train, y_train, X_val, y_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model:  Random Forest\n"
     ]
    }
   ],
   "source": [
    "# Sort results by the best accuracy.\n",
    "results.sort(key = lambda x: x[0], reverse=False)\n",
    "\n",
    "print(\"Best Model: \", results[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning\n",
    "`Random Forest` has the best performance.\n",
    "\n",
    "We will now run a Grid Search on it to see which parameters might be most effective. We have already run a Randomized Grid Search (in the past) to see how we should narrow down our parameter space. \n",
    "\n",
    "    > NOTE: We are choosing to use a smaller `max_depth`. We do this so it can act as a regularization term. We may not get better results (than a higher max_depth), but we will get a more general model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin  RandomForest\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 22.7min\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed: 26.5min\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed: 32.2min\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed: 39.6min\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed: 44.7min\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed: 51.5min\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed: 66.4min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed: 79.5min\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed: 97.3min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed: 110.5min\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed: 125.7min\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed: 140.3min\n",
      "[Parallel(n_jobs=-1)]: Done 241 tasks      | elapsed: 160.5min\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed: 181.2min\n",
      "[Parallel(n_jobs=-1)]: Done 289 tasks      | elapsed: 216.0min\n",
      "[Parallel(n_jobs=-1)]: Done 314 tasks      | elapsed: 231.9min\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed: 252.8min\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed: 275.4min\n",
      "[Parallel(n_jobs=-1)]: Done 397 tasks      | elapsed: 299.3min\n",
      "[Parallel(n_jobs=-1)]: Done 432 out of 432 | elapsed: 330.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Best Score:  -0.07681857397299258\n",
      "\t- Time Elapsed:  19862.022178649902\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def grid_search(clf, params, model_name, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Run Grid Search on a model\"\"\"\n",
    "    print(\"Begin \", model_name)\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    clf = GridSearchCV(clf(), params, refit=False, scoring='neg_mean_squared_log_error', cv=3, n_jobs=-1, verbose=10)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"\\t- Best Score: \", clf.best_score_)\n",
    "    print(\"\\t- Time Elapsed: \", time.time() - start)\n",
    "    \n",
    "    return (clf.best_score_, clf, model_name)\n",
    "\n",
    "params_rf = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10,30,50,70], # Making this small to act as regularization.\n",
    "    'max_features': ['auto',0.9,0.8],\n",
    "    'min_samples_leaf': [1, 3],\n",
    "    'min_samples_split': [4, 6],\n",
    "    'n_estimators': [400,600,800]\n",
    "}\n",
    "\n",
    "models_to_tune = [\n",
    "    (RandomForestRegressor, params_rf, \"RandomForest\")\n",
    "]\n",
    "\n",
    "tuned_results = []\n",
    "for model in models_to_tune:\n",
    "    tuned_results += [grid_search(model[0], model[1], model[2], X_train, y_train, X_val, y_val)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Parameters\n",
    "We can view the best parameters by extracting `cv_results_`. This will allow us to see how the best parameters compared to the other parameters.\n",
    "\n",
    "During the Hyper Parameter Tuning process, this was useful in order to narrow the search space down. For example, We saw consistently worse results during the following:\n",
    "* bootstrap : False\n",
    "* max_features : sq_rt\n",
    "\n",
    "Armed with this knowledge, we were able to reduce the number of parameters we need to search over, so GridSearch might be more efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>774.786263</td>\n",
       "      <td>6.446918</td>\n",
       "      <td>7.233926</td>\n",
       "      <td>0.955843</td>\n",
       "      <td>True</td>\n",
       "      <td>50</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>800</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 50, 'max_feat...</td>\n",
       "      <td>-0.077626</td>\n",
       "      <td>-0.077542</td>\n",
       "      <td>-0.075287</td>\n",
       "      <td>-0.076819</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>774.011335</td>\n",
       "      <td>3.330593</td>\n",
       "      <td>26.130245</td>\n",
       "      <td>5.434318</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>800</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 30, 'max_feat...</td>\n",
       "      <td>-0.077611</td>\n",
       "      <td>-0.077623</td>\n",
       "      <td>-0.075236</td>\n",
       "      <td>-0.076823</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>656.206079</td>\n",
       "      <td>5.563231</td>\n",
       "      <td>7.214401</td>\n",
       "      <td>0.934333</td>\n",
       "      <td>True</td>\n",
       "      <td>50</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>600</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 50, 'max_feat...</td>\n",
       "      <td>-0.077769</td>\n",
       "      <td>-0.077457</td>\n",
       "      <td>-0.075251</td>\n",
       "      <td>-0.076826</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>770.665531</td>\n",
       "      <td>1.546265</td>\n",
       "      <td>6.209767</td>\n",
       "      <td>0.058614</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>800</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 30, 'max_feat...</td>\n",
       "      <td>-0.077631</td>\n",
       "      <td>-0.077678</td>\n",
       "      <td>-0.075172</td>\n",
       "      <td>-0.076827</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>575.294881</td>\n",
       "      <td>1.597125</td>\n",
       "      <td>4.497974</td>\n",
       "      <td>0.038676</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 30, 'max_feat...</td>\n",
       "      <td>-0.077564</td>\n",
       "      <td>-0.077639</td>\n",
       "      <td>-0.075282</td>\n",
       "      <td>-0.076828</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "83     774.786263      6.446918         7.233926        0.955843   \n",
       "47     774.011335      3.330593        26.130245        5.434318   \n",
       "73     656.206079      5.563231         7.214401        0.934333   \n",
       "44     770.665531      1.546265         6.209767        0.058614   \n",
       "46     575.294881      1.597125         4.497974        0.038676   \n",
       "\n",
       "   param_bootstrap param_max_depth param_max_features param_min_samples_leaf  \\\n",
       "83            True              50               auto                      3   \n",
       "47            True              30               auto                      3   \n",
       "73            True              50               auto                      1   \n",
       "44            True              30               auto                      3   \n",
       "46            True              30               auto                      3   \n",
       "\n",
       "   param_min_samples_split param_n_estimators  \\\n",
       "83                       6                800   \n",
       "47                       6                800   \n",
       "73                       4                600   \n",
       "44                       4                800   \n",
       "46                       6                600   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "83  {'bootstrap': True, 'max_depth': 50, 'max_feat...          -0.077626   \n",
       "47  {'bootstrap': True, 'max_depth': 30, 'max_feat...          -0.077611   \n",
       "73  {'bootstrap': True, 'max_depth': 50, 'max_feat...          -0.077769   \n",
       "44  {'bootstrap': True, 'max_depth': 30, 'max_feat...          -0.077631   \n",
       "46  {'bootstrap': True, 'max_depth': 30, 'max_feat...          -0.077564   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "83          -0.077542          -0.075287        -0.076819        0.001083   \n",
       "47          -0.077623          -0.075236        -0.076823        0.001122   \n",
       "73          -0.077457          -0.075251        -0.076826        0.001121   \n",
       "44          -0.077678          -0.075172        -0.076827        0.001170   \n",
       "46          -0.077639          -0.075282        -0.076828        0.001094   \n",
       "\n",
       "    rank_test_score  \n",
       "83                1  \n",
       "47                2  \n",
       "73                3  \n",
       "44                4  \n",
       "46                5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab parameter results\n",
    "param_results = pd.DataFrame(tuned_results[0][1].cv_results_).sort_values('rank_test_score')\n",
    "\n",
    "# Write Parameters to CSV\n",
    "import os\n",
    "# if file does not exist write header \n",
    "if not os.path.isfile('random_forest_params.csv'):\n",
    "    param_results.to_csv('random_forest_params.csv', header=True)\n",
    "else: # else it exists so append without writing the header\n",
    "    param_results.to_csv('random_forest_params.csv', mode='a', header=False)\n",
    "\n",
    "param_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "\n",
    "We will evaluate the performance of the `RandomForestRegressor` model on the \n",
    "* Training Set\n",
    "* Validation Set\n",
    "* Testing Set\n",
    "\n",
    "Understanding how the results varies within each of the data sets will help us understand how well the model is generalizing to new data. We expect to see a similar results across all data sets.\n",
    "\n",
    "> NOTE: We will only using the results on the `testing` for determining to accept or decline our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed:  747.2535169124603\n",
      "Training Mean Squared Log Error:  0.028079280506422465\n",
      "Validation Mean Squared Log Error:  0.07418327885404077\n",
      "Testing Mean Squared Log Error:  0.07684279699857259\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "best_clf = RandomForestRegressor(**tuned_results[0][1].best_params_).fit(X_train, y_train)\n",
    "\n",
    "print(\"Time Elapsed: \", time.time() - start)\n",
    "\n",
    "predictions = best_clf.predict(X_train)\n",
    "msle = mean_squared_log_error(y_train, predictions)\n",
    "print(\"Training Mean Squared Log Error: \", msle)\n",
    "\n",
    "predictions = best_clf.predict(X_val)\n",
    "msle = mean_squared_log_error(y_val, predictions)\n",
    "print(\"Validation Mean Squared Log Error: \", msle)\n",
    "\n",
    "predictions = best_clf.predict(X_test)\n",
    "msle = mean_squared_log_error(y_test, predictions)\n",
    "print(\"Testing Mean Squared Log Error: \", msle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zillow's Zestimate\n",
    "Zillow presents their results via a table that displays the following:\n",
    "* Median Error\n",
    "* Homes With ZESTIMATES\n",
    "* Within 5% of Sale Price\n",
    "* Within 10% of Sale Price\n",
    "* Within 20% of Sale Price\n",
    "\n",
    "We will develop the same metrics from our results and compare them to Zillows results on `Pittsburgh PA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# Concatentate Predictions with Actual\n",
    "comparison = pd.concat([pd.Series(predictions), y_test], axis=1)\n",
    "comparison = comparison.rename(columns={0:'PREDICTION'})\n",
    "\n",
    "# Calculate `Percent Error`\n",
    "## |(Prediction - SalePrice) / SalePrice|\n",
    "comparison['PERCENT ERROR'] = abs((comparison['PREDICTION'] - comparison['SALEPRICE']) / comparison['SALEPRICE'])\n",
    "\n",
    "# Write to CSV\n",
    "comparison.to_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREDICTION</th>\n",
       "      <th>SALEPRICE</th>\n",
       "      <th>PERCENT ERROR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53860.034574</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>0.145079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47787.256382</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>0.062995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>125579.718215</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>0.091998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>344395.786402</td>\n",
       "      <td>378000.0</td>\n",
       "      <td>0.088900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132732.113023</td>\n",
       "      <td>146000.0</td>\n",
       "      <td>0.090876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PREDICTION  SALEPRICE  PERCENT ERROR\n",
       "0   53860.034574    63000.0       0.145079\n",
       "1   47787.256382    51000.0       0.062995\n",
       "2  125579.718215   115000.0       0.091998\n",
       "3  344395.786402   378000.0       0.088900\n",
       "4  132732.113023   146000.0       0.090876"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>METROPOLITAN AREA</th>\n",
       "      <th>MEDIAN ERROR</th>\n",
       "      <th>HOMES WITH ESTIMATE</th>\n",
       "      <th>WITH 5% OF SALEPRICE</th>\n",
       "      <th>WITH 10% OF SALEPRICE</th>\n",
       "      <th>WITH 20% OF SALEPRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Our Results</th>\n",
       "      <td>Pittsburgh, PA</td>\n",
       "      <td>10.409506</td>\n",
       "      <td>23704</td>\n",
       "      <td>27.62403</td>\n",
       "      <td>48.439082</td>\n",
       "      <td>73.202835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zillow</th>\n",
       "      <td>Pittsburgh, PA</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>10900</td>\n",
       "      <td>77.60000</td>\n",
       "      <td>93.200000</td>\n",
       "      <td>98.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            METROPOLITAN AREA  MEDIAN ERROR  HOMES WITH ESTIMATE  \\\n",
       "Our Results    Pittsburgh, PA     10.409506                23704   \n",
       "Zillow         Pittsburgh, PA      2.500000                10900   \n",
       "\n",
       "             WITH 5% OF SALEPRICE  WITH 10% OF SALEPRICE  \\\n",
       "Our Results              27.62403              48.439082   \n",
       "Zillow                   77.60000              93.200000   \n",
       "\n",
       "             WITH 20% OF SALEPRICE  \n",
       "Our Results              73.202835  \n",
       "Zillow                   98.400000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain Metrics to create table.\n",
    "\n",
    "area = 'Pittsburgh, PA'\n",
    "median_error = comparison['PERCENT ERROR'].median() * 100\n",
    "total_estimates = comparison.shape[0]\n",
    "five_percent = comparison[comparison['PERCENT ERROR'] <= 0.05].shape[0] / comparison.shape[0] * 100\n",
    "ten_percent = comparison[comparison['PERCENT ERROR'] <= 0.10].shape[0] / comparison.shape[0] * 100\n",
    "twenty_percent = comparison[comparison['PERCENT ERROR'] <= 0.20].shape[0] / comparison.shape[0] * 100\n",
    "\n",
    "column_names = ['METROPOLITAN AREA', 'MEDIAN ERROR', 'HOMES WITH ESTIMATE', 'WITH 5% OF SALEPRICE', 'WITH 10% OF SALEPRICE', 'WITH 20% OF SALEPRICE']\n",
    "\n",
    "results_lst = [area, median_error, total_estimates, five_percent, ten_percent, twenty_percent]\n",
    "zillow_lst = ['Pittsburgh, PA', 2.5, 10900, 77.6, 93.2, 98.4]\n",
    "\n",
    "results = pd.DataFrame([results_lst, zillow_lst], index=['Our Results', 'Zillow'], columns=column_names)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance:\n",
    "\n",
    "### Random Forest Feature Importance\n",
    "Random Forest has a built in feature importance, which will tell us how important each feature is. However, this does not tell us what kind of values the features should have.\n",
    "\n",
    "\n",
    "### SHAP (SHapley Additive exPlanations)\n",
    "SHAP measures the impact of variables taking into account the interaction with other variables. \n",
    "\n",
    "This will be better than the feature importances found in Random Forest because we can now see how the value of each feature affects the final result.\n",
    "\n",
    "Reference: \n",
    "* https://towardsdatascience.com/explain-your-model-with-the-shap-values-bc36aac4de3d\n",
    "\n",
    "* https://blog.datascienceheroes.com/how-to-interpret-shap-values-in-r/Which features are more important to XGBoost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-eeb02d10874f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimportances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Feature Importances'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "features = X.columns.tolist()\n",
    "importances = results[0][1].feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "print(shap.__version__)\n",
    "\n",
    "# May need to run the following as system admin in anaconda command prompt\n",
    "## conda install -c conda-forge shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = shap.TreeExplainer(results[0][1]).shap_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train) # Change to Red and Green"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "We tested the following models:\n",
    "* XGBoost\n",
    "* RandomForest\n",
    "* KNearest Neighbors\n",
    "* Support Vector Machine\n",
    "* Gradient Boosted Decision Tree\n",
    "\n",
    "The best performing model was `RandomForest`. Once we found the best performing model, we implemented a `Grid Search` which aimed to exhaustively explore a specified grid and find the best parameters. Once we tuned our parameters, we tested our predictions on our Training, Validation, and Testing set.\n",
    "\n",
    "Our testing set had a RMSE of `4780.84`. This indicates that we still have a lot of room for improvements, so we might want to attempt a different approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
